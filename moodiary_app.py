# --- 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager
import random
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import requests
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig

# --- 2. ê¸°ë³¸ ì„¤ì • ë° ê²½ë¡œ ---
KOBERT_BASE_MODEL = "monologg/kobert"
KOBERT_SAVED_REPO = "Young-jin/kobert-moodiary-app" 
TMDB_BASE_URL = "https://api.themoviedb.org/3"

# í°íŠ¸ ì„¤ì • (ì—ëŸ¬ê°€ ë‚˜ë„ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰)
try:
    font_path = "c:/Windows/Fonts/malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)
except FileNotFoundError:
    pass 

FINAL_EMOTIONS = ["í–‰ë³µ", "ìŠ¬í””", "ë¶„ë…¸", "í˜ë“¦", "ë†€ëŒ"]

# --- 3. KoBERT ëª¨ë¸ ë¡œë“œ (num_labels=6 ê°•ì œ) ---
@st.cache_resource
def load_kobert_model():
    try:
        CORRECT_ID_TO_LABEL = {
            0: 'ë¶„ë…¸', 1: 'ê¸°ì¨', 2: 'ë¶ˆì•ˆ', 
            3: 'ë‹¹í™©', 4: 'ìŠ¬í””', 5: 'ìƒì²˜'
        }
        config = AutoConfig.from_pretrained(
            KOBERT_BASE_MODEL, 
            trust_remote_code=True,
            num_labels=6,
            id2label=CORRECT_ID_TO_LABEL,
            label2id={label: id for id, label in CORRECT_ID_TO_LABEL.items()}
        )
        tokenizer = AutoTokenizer.from_pretrained(
            KOBERT_BASE_MODEL, 
            trust_remote_code=True
        )
        model = AutoModelForSequenceClassification.from_pretrained(
            KOBERT_SAVED_REPO, 
            config=config, 
            trust_remote_code=True,
            ignore_mismatched_sizes=False
        )
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        post_processing_map = getattr(model.config, 'post_processing_map', None)
        if post_processing_map is None:
            post_processing_map = {
                'ê¸°ì¨': 'í–‰ë³µ', 'ìŠ¬í””': 'ìŠ¬í””', 'ìƒì²˜': 'ìŠ¬í””',
                'ë¶ˆì•ˆ': 'í˜ë“¦', 'ë‹¹í™©': 'ë†€ëŒ', 'ë¶„ë…¸': 'ë¶„ë…¸'
            }
        return model, tokenizer, device, post_processing_map
    except Exception as e:
        st.error(f"ğŸš¨ AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None, None, None, None

# --- 4. í•µì‹¬ ë¶„ì„ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
def analyze_diary_kobert(text, model, tokenizer, device, post_processing_map):
    if not text:
        return None, 0.0
    encodings = tokenizer(
        text, truncation=True, padding=True, max_length=128, return_tensors="pt"
    )
    input_ids = encodings['input_ids'].to(device)
    attention_mask = encodings['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
    probabilities = torch.softmax(logits, dim=1)
    predicted_class_id = torch.argmax(probabilities, dim=1).cpu().numpy()[0]
    score = probabilities[0, predicted_class_id].item()
    id_to_label = model.config.id2label
    original_label = id_to_label[predicted_class_id]
    final_emotion = post_processing_map.get(original_label, original_label)
    return final_emotion, score

# --- 5. API ì—°ê²° í•¨ìˆ˜ (Spotify - ë³€ê²½ ì—†ìŒ) ---
@st.cache_resource
def get_spotify_client():
    spotify_creds = st.secrets.get("spotify", {})
    client_id = spotify_creds.get("client_id")
    client_secret = spotify_creds.get("client_secret")
    if not client_id or not client_secret:
        return None
    try:
        client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)
        sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)
        return sp
    except Exception as e:
        return None 

# --- 6. ì¶”ì²œ í•¨ìˆ˜ (Spotify ì˜¤ë¥˜ ìˆ˜ì •, TMDB ëœë¤ ì¶”ì²œ) ---
def get_spotify_ai_recommendations(emotion):
    sp_client = get_spotify_client()
    if not sp_client: return ["Spotify ì—°ê²° ì‹¤íŒ¨ (í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨)"]
    emotion_keywords = { 
        "í–‰ë³µ": ["K-Pop Happy", "ì‹ ë‚˜ëŠ”"], 
        "ìŠ¬í””": ["K-Pop Ballad", "ìŠ¬í”ˆ", "ì´ë³„"], 
        "ë¶„ë…¸": ["K-Rock", "í™”ë‚  ë•Œ", "ìŠ¤íŠ¸ë ˆìŠ¤"], 
        "í˜ë“¦": ["K-Pop healing", "ìœ„ë¡œ", "ì§€ì¹  ë•Œ"], 
        "ë†€ëŒ": ["K-Pop Party", "ì‹ ë‚˜ëŠ”"], 
    }
    query = random.choice(emotion_keywords.get(emotion, ["K-Pop"]))
    try:
        results = sp_client.search(q=query, type='playlist', limit=20, market="KR")
        if not results: return [f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."]
        playlists = results.get('playlists', {}).get('items')
        if not playlists: return [f"'{query}' ê´€ë ¨ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”."]
        
        for _ in range(3): 
            random_playlist = random.choice(playlists)
            playlist_id = random_playlist['id']
            tracks_results = sp_client.playlist_items(playlist_id, limit=50)
            
            if not tracks_results or 'items' not in tracks_results:
                continue 

            tracks = []
            for item in tracks_results['items']:
                 if item and item.get('track') and item['track'].get('artists') and item['track'].get('name'):
                     if item['track']['artists'] and item['track']['artists'][0].get('name'):
                         tracks.append(item['track'])
            
            if tracks: 
                random_tracks = random.sample(tracks, min(3, len(tracks)))
                return [f"{track['name']} - {track['artists'][0]['name']}" for track in random_tracks]

        return ["ì¶”ì²œí•  ë§Œí•œ ë…¸ë˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¬¸ì œ)"]

    except Exception as e: 
        return [f"Spotify AI ê²€ìƒ‰ ì˜¤ë¥˜: {e}"]

def get_tmdb_recommendations(emotion):
    tmdb_creds = st.secrets.get("tmdb", {})
    current_tmdb_key = tmdb_creds.get("api_key", "")
    if not current_tmdb_key:
        return [{"text": "TMDB ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", "poster": None}]

    TMDB_GENRE_MAP = {
        "í–‰ë³µ": "35|10749|10751|10402|16",
        "ë¶„ë…¸": "28|12|35|878",
        "ìŠ¬í””": "35|10751|16|14",
        "í˜ë“¦": "35|10751|16|14",
        "ë†€ëŒ": "35|10751|16|14"
    }
    genre_ids_string = TMDB_GENRE_MAP.get(emotion)
    if not genre_ids_string:
        return [{"text": f"[{emotion}]ì— ëŒ€í•œ ì¥ë¥´ ë§µí•‘ì´ ì—†ìŠµë‹ˆë‹¤.", "poster": None}]

    endpoint = "https://api.themoviedb.org/3/discover/movie"
    params = {
        "api_key": current_tmdb_key,
        "language": "ko-KR",
        "sort_by": "popularity.desc",
        "with_genres": genre_ids_string,
        "page": 1,
        "vote_count.gte": 100
    }
    try:
        response = requests.get(endpoint, params=params)
        response.raise_for_status()
        data = response.json()

        if not data.get('results'):
            return [{"text": f"[{emotion} ì¥ë¥´]ì˜ ì¸ê¸° ì˜í™”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "poster": None}]

        popular_movies = data['results']
        selected_movies = popular_movies if len(popular_movies) <= 3 else random.sample(popular_movies, 3)

        recs = []
        for m in selected_movies:
            title = m.get('title', 'ì œëª©ì—†ìŒ')
            year = (m.get('release_date') or '')[:4] or "N/A"
            rating = m.get('vote_average', 0.0)
            poster = f"https://image.tmdb.org/t/p/w500{m['poster_path']}" if m.get('poster_path') else None
            recs.append({
                "text": f"{title} ({year}) (í‰ì : {rating:.1f})",
                "poster": poster
            })
        return recs

    except requests.exceptions.RequestException as e:
        return [{"text": f"TMDb API í˜¸ì¶œ ì‹¤íŒ¨: {e}", "poster": None}]

def recommend(final_emotion):
    music_recs = get_spotify_ai_recommendations(final_emotion)
    movie_recs = get_tmdb_recommendations(final_emotion)
    return {'ìŒì•…': music_recs, 'ì˜í™”': movie_recs}

# --- 7. Streamlit UI êµ¬ì„± (ìµœì¢… í´ë¦° ë²„ì „) ---
st.set_page_config(layout="wide")
st.title("MOODIARY ğŸ’–")

model, tokenizer, device, post_processing_map = load_kobert_model()

if 'diary_text' not in st.session_state: st.session_state.diary_text = ""
if 'final_emotion' not in st.session_state: st.session_state.final_emotion = None

col1, col2 = st.columns([3, 1])
with col1:
    st.markdown("### ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:")
    st.text_area(
        "ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:",
        key='diary_text', 
        height=250, 
        label_visibility="hidden"
    )
    
with col2:
    st.write(" "); st.write(" ")
    
    def handle_analyze_click():
        diary_content = st.session_state.diary_text
        if not diary_content.strip(): 
            st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            st.session_state.final_emotion = None
        elif model is None: 
            st.error("AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
            st.session_state.final_emotion = None
        else:
            with st.spinner('AIê°€ ì¼ê¸°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (KoBERT)'):
                emotion, score = analyze_diary_kobert(
                    diary_content, model, tokenizer, device, post_processing_map
                )
                st.session_state.final_emotion = emotion
                
    st.button("ğŸ” ë‚´ í•˜ë£¨ ê°ì • ë¶„ì„í•˜ê¸°", type="primary", on_click=handle_analyze_click)

if st.session_state.final_emotion:
    final_emotion = st.session_state.final_emotion
    st.subheader(f"ì˜¤ëŠ˜ í•˜ë£¨ì˜ í•µì‹¬ ê°ì •ì€ '{final_emotion}' ì…ë‹ˆë‹¤.")
    
    st.divider()
    st.subheader(f"'{final_emotion}' ê°ì •ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ Moodiary ì¶”ì²œ")
    with st.spinner(f"'{final_emotion}'ì— ë§ëŠ” ì¶”ì²œ í•­ëª©ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
        recs = recommend(final_emotion)
        
    rec_col1, rec_col2 = st.columns(2)
    
    with rec_col1:
        st.markdown("#### ğŸµ ì´ëŸ° ìŒì•…ë„ ë“¤ì–´ë³´ì„¸ìš”?")
        if recs['ìŒì•…']:
            for item in recs['ìŒì•…']: st.write(f"- {item}")
        else: st.write("- ì¶”ì²œì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.")
        
    # â­ï¸â­ï¸â­ï¸ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤ â­ï¸â­ï¸â­ï¸
    # (ë“¤ì—¬ì“°ê¸°ë¥¼ `with rec_col1`ê³¼ ë™ì¼í•˜ê²Œ ë§ì·„ìŠµë‹ˆë‹¤)
    with rec_col2:
        st.markdown("#### ğŸ¬ ì´ëŸ° ì˜í™”ë„ ì¶”ì²œí•´ìš”?")
        if recs['ì˜í™”']:
            for item in recs['ì˜í™”']:
                if isinstance(item, dict):
                    # í¬ìŠ¤í„°ê°€ ìˆìœ¼ë©´ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ë³´ì—¬ì¤ë‹ˆë‹¤.
                    if item.get("poster"):
                        st.image(item["poster"], width=160)
                    # í…ìŠ¤íŠ¸ë¥¼ ë‚˜ì¤‘ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
                    st.write(f"- {item.get('text','')}")
                else:
                    # (í˜¹ì‹œë¼ë„ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ê°€ ë°˜í™˜ë  ê²½ìš° ëŒ€ë¹„)
                    st.write(f"- {item}")
        else:
            st.write("- ì¶”ì²œì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.")
